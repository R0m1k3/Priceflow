# Amazon France Scraper - Documentation

## ğŸ¯ Vue d'ensemble

Le scraper Amazon France est un systÃ¨me de recherche de produits conÃ§u pour Ã©viter la dÃ©tection anti-bot d'Amazon. Il utilise Crawl4AI avec des techniques avancÃ©es d'anti-dÃ©tection.

## ğŸ›¡ï¸ Techniques anti-dÃ©tection

### 1. User-Agent rotatif
- Pool de 5 User-Agents rÃ©alistes (Chrome, Firefox, Safari, Edge)
- Rotation alÃ©atoire Ã  chaque requÃªte
- Headers complets mimant un vrai navigateur

### 2. Proxies rÃ©sidentiels
- **10 proxies rotatifs** configurÃ©s
- SÃ©lection alÃ©atoire pour chaque recherche
- Format: `ip:port:username:password`
- Configuration dans `/app/core/search_config.py`

### 3. DÃ©lais alÃ©atoires
- Entre **1.5 et 4 secondes** entre les requÃªtes
- Simule le comportement humain
- Ã‰vite les patterns de bot

### 4. Headers HTTP rÃ©alistes
```python
{
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,...",
    "Accept-Language": "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br",
    "DNT": "1",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    ...
}
```

### 5. Crawl4AI configuration
- `headless=True` - Mode invisible
- `--disable-blink-features=AutomationControlled` - DÃ©sactive la dÃ©tection d'automation
- `wait_until="networkidle"` - Attend le chargement complet
- `remove_overlay_elements=True` - Supprime les popups
- Acceptation automatique des cookies

## ğŸ“¦ DonnÃ©es extraites

Pour chaque produit, le scraper extrait :

| Champ | Type | Description |
|-------|------|-------------|
| `title` | string | Titre du produit |
| `url` | string | URL Amazon |
| `price` | float | Prix actuel en EUR |
| `original_price` | float | Prix original si promotion |
| `rating` | float | Note sur 5 Ã©toiles |
| `reviews_count` | int | Nombre d'avis |
| `image_url` | string | URL de l'image |
| `in_stock` | bool | DisponibilitÃ© |
| `prime` | bool | Ã‰ligible Prime |
| `sponsored` | bool | Produit sponsorisÃ© |

## ğŸš€ Utilisation

### Backend (Python)

```python
from app.services.amazon_scraper import scrape_amazon_search

# Recherche simple
products = await scrape_amazon_search("aspirateur", max_results=20)

for product in products:
    print(f"{product.title} - {product.price}â‚¬")
```

### API REST

```bash
# Endpoint SSE (Server-Sent Events)
GET /api/amazon/search?q=aspirateur&max_results=20

# Health check
GET /api/amazon/health
```

### Frontend (React)

```javascript
// EventSource pour SSE
const eventSource = new EventSource(`/api/amazon/search?q=${query}&max_results=20`);

eventSource.addEventListener('progress', (event) => {
    const data = JSON.parse(event.data);
    // data.status: 'searching', 'completed', 'error'
    // data.results: array of products
});
```

AccÃ¨s direct : **http://localhost/amazon** (aprÃ¨s connexion)

## ğŸ§ª Tests

### Script de test complet

```bash
# Lancer tous les tests
python test_amazon_scraper.py
```

Tests inclus :
1. âœ… Recherche basique (5 produits)
2. âœ… RequÃªtes multiples (clavier, souris, casque)
3. âœ… VÃ©rification anti-dÃ©tection

### Test manuel simple

```python
import asyncio
from app.services.amazon_scraper import test_amazon_scraper

asyncio.run(test_amazon_scraper())
```

## âš™ï¸ Configuration

### Proxies

Modifiez `/app/core/search_config.py` :

```python
AMAZON_PROXY_LIST_RAW = [
    "ip1:port1:user1:pass1",
    "ip2:port2:user2:pass2",
    # ... ajoutez vos proxies
]
```

### User-Agents

Ajoutez dans `/app/services/amazon_scraper.py` :

```python
AMAZON_USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; ...) Chrome/131.0.0.0",
    # ... ajoutez vos user-agents
]
```

### DÃ©lais

Modifiez la fonction `random_delay()` :

```python
async def random_delay(min_seconds=1.5, max_seconds=4.0):
    delay = random.uniform(min_seconds, max_seconds)
    await asyncio.sleep(delay)
```

## ğŸ” SÃ©lecteurs CSS Amazon

Le scraper utilise les sÃ©lecteurs suivants (mis Ã  jour pour 2024) :

```python
# Cartes produits
product_cards = soup.find_all('div', {'data-component-type': 's-search-result'})

# Titre
title_elem = card.select_one('h2 a span, h2 span')

# Prix actuel
price_elem = card.select_one('.a-price .a-offscreen')

# Prix original (promo)
original_price_elem = card.select_one('.a-price.a-text-price .a-offscreen')

# Note
rating_elem = card.select_one('[aria-label*="Ã©toile"], [aria-label*="star"]')

# Nombre d'avis
reviews_elem = card.select_one('[aria-label*="Ã©toile"] + span')

# Image
img_elem = card.select_one('img.s-image')

# Prime
prime = card.select_one('[aria-label*="Prime"], i.a-icon-prime')
```

## ğŸ“Š Performances

- **Vitesse** : ~3-5 secondes pour 20 produits
- **Taux de succÃ¨s** : ~95% (avec proxies)
- **Limite recommandÃ©e** : Max 20 produits par requÃªte
- **DÃ©lai entre requÃªtes** : 2-5 secondes

## âš ï¸ Limitations connues

1. **CAPTCHA** : Peut survenir en cas d'utilisation intensive
   - Solution : Rotation des proxies + dÃ©lais plus longs

2. **GÃ©olocalisation** : Les proxies doivent Ãªtre franÃ§ais/europÃ©ens
   - Amazon.fr peut bloquer les IPs non-europÃ©ennes

3. **Structure HTML** : Amazon peut modifier ses sÃ©lecteurs
   - VÃ©rifier rÃ©guliÃ¨rement les sÃ©lecteurs CSS

4. **Rate limiting** : Amazon limite les requÃªtes par IP
   - Utiliser les proxies rotatifs

## ğŸ› Debugging

### Logs

Les logs dÃ©taillÃ©s sont disponibles dans la console :

```python
logger.info(f"ğŸ” Searching Amazon France: {query}")
logger.info(f"ğŸ“ URL: {search_url}")
logger.debug(f"ğŸ­ User-Agent: {user_agent}")
logger.debug(f"ğŸŒ Using proxy: {proxy['server']}")
```

### Messages d'erreur courants

| Erreur | Cause | Solution |
|--------|-------|----------|
| `CAPTCHA detected` | Trop de requÃªtes | Attendre + changer de proxy |
| `Bot detection triggered` | Mauvais User-Agent | VÃ©rifier USER_AGENTS |
| `No products found` | RequÃªte vide ou blocage | VÃ©rifier la recherche |
| `Timeout` | Connexion lente | Augmenter `page_timeout` |

### Mode debug Crawl4AI

```python
browser_config = BrowserConfig(
    headless=False,  # Voir le navigateur
    verbose=True,     # Logs dÃ©taillÃ©s
    ...
)
```

## ğŸ“ˆ Ã‰volutions futures

- [ ] Cache Redis pour Ã©viter les requÃªtes rÃ©pÃ©tÃ©es
- [ ] Pagination automatique (>20 produits)
- [ ] DÃ©tection automatique de CAPTCHA
- [ ] RÃ©solution de CAPTCHA (service tiers)
- [ ] Scraping des dÃ©tails produit (description, specs)
- [ ] Support Amazon.de, Amazon.es, etc.
- [ ] Monitoring des prix en temps rÃ©el
- [ ] Alertes de baisse de prix

## ğŸ” SÃ©curitÃ© & LÃ©galitÃ©

âš ï¸ **Important** : Ce scraper est destinÃ© Ã  un usage personnel uniquement.

- âœ… Usage personnel/Ã©ducatif
- âœ… Recherche de produits
- âœ… Comparaison de prix
- âŒ Revente de donnÃ©es
- âŒ Usage commercial intensif
- âŒ Contournement de CAPTCHA Ã  grande Ã©chelle

Respectez les [Conditions d'utilisation Amazon](https://www.amazon.fr/gp/help/customer/display.html?nodeId=201909000).

## ğŸ“ Support

En cas de problÃ¨me :

1. VÃ©rifier les logs (`logger.info/debug/error`)
2. Tester avec le script `test_amazon_scraper.py`
3. VÃ©rifier la configuration des proxies
4. Consulter la [documentation Crawl4AI](https://crawl4ai.com/)

## ğŸ‰ CrÃ©dits

- **Crawl4AI** : Framework de scraping IA
- **BeautifulSoup** : Parsing HTML
- **FastAPI** : API backend
- **React** : Interface frontend
- **Shadcn UI** : Composants UI
